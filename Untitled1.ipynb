{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40aaf775-0ba9-4880-9755-cb3c55e83032",
   "metadata": {},
   "source": [
    "### This is a script to run periodic model performance evaluation using the most recent 1 day of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9f461e9-3384-473a-9845-ac39d45ea2bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/projects_gcp_cpu/spx/src'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, time, warnings, random, shap, requests, optuna, datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import functools as ft\n",
    "import yfinance as yf\n",
    "\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder, OrdinalEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, train_test_split, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, r2_score, mean_squared_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "time0 = time.time()\n",
    "\n",
    "os.chdir('/home/jupyter/projects_gcp_cpu/spx/src')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12186264-c8e7-4596-84d2-04541acc0853",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32cbd15-732c-4e66-b4f2-f8b85a243147",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df['time'] = df.index.time\n",
    "df['date'] = df.index.date\n",
    "\n",
    "df = df.fillna(method='ffill')\n",
    "dayclose = df[df.time==datetime.time(15, 58, 0)]\n",
    "dayopen = df[df.time==datetime.time(9, 30, 0)]\n",
    "dayopen.reset_index(drop=True, inplace=True)\n",
    "dayclose.reset_index(drop=True, inplace=True)\n",
    "dayclose.sort_values(by='date')\n",
    "display(df, dayopen.head(), dayclose.head())\n",
    "df0 = df.copy()\n",
    "\n",
    "# df['hour'] = pd.to_datetime(df['time'], format='%H:%M:%S').dt.hour\n",
    "# df['minute'] = pd.to_datetime(df['time'], format='%H:%M:%S').dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f61fd6a-49c9-41f5-b21b-ff749dd7e9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### now i wanna do feature engineering for all assets \n",
    "\n",
    "asset_list = ['Spx', 'Nasdaq', 'Russel', 'EMXC', 'EEMA', 'EEM', 'VTHR']\n",
    "\n",
    "for asset in asset_list:\n",
    "    \n",
    "    df[asset + '_ret'] = 100*(df[asset]/df[asset].shift(1)-1)\n",
    "    df['s_' + asset + '_ret_1prd'] = (100*(df[asset]/df[asset].shift(1)-1)).shift(1)\n",
    "    df['s_' + asset + '_ret_2prd'] = (100*(df[asset]/df[asset].shift(2)-1)).shift(1)\n",
    "    df['s_' + asset + '_ret_4prd'] = (100*(df[asset]/df[asset].shift(4)-1)).shift(1)\n",
    "    display(df.shape, df.head(5))\n",
    "\n",
    "    df.loc[df.time < datetime.time(9, 32, 0), 's_' + asset + '_1prd'] = np.nan\n",
    "    df.loc[df.time < datetime.time(9, 33, 0), 's_' + asset + '_2prd'] = np.nan\n",
    "    df.loc[df.time < datetime.time(9, 35, 0), 's_' + asset + '_4prd'] = np.nan\n",
    "\n",
    "    dayopen.rename(columns={asset:asset+'_open'}, inplace=True)\n",
    "    dayopen.head()\n",
    "    dayclose.rename(columns={asset:asset+'_close'}, inplace=True)\n",
    "    dayclose_l1 = dayclose.copy()\n",
    "    dayclose_l2 = dayclose.copy()\n",
    "    dayclose_l1[asset+'_close_l1'] = dayclose_l1[asset+'_close'].shift(1)\n",
    "    dayclose_l2[asset+'_close_l2'] = dayclose_l2[asset+'_close'].shift(2)\n",
    "\n",
    "    # display(dayclose_l1.head(), dayclose_l2.head())\n",
    "\n",
    "    df = pd.merge(df, dayopen[['date', asset + '_open']], on=['date'], how='left')\n",
    "    df = pd.merge(df, dayclose_l1[['date', asset + '_close_l1']], on=['date'], how='left')\n",
    "    df = pd.merge(df, dayclose_l2[['date', asset + '_close_l2']], on=['date'], how='left')\n",
    "\n",
    "    df['s_' + asset + '_ret_open'] = (100*(df[asset]/df[asset + '_open']-1)).shift(1)\n",
    "    df['s_' + asset + '_ret_close1'] = (100*(df[asset]/df[asset + '_close_l1']-1)).shift(1)\n",
    "    df['s_' + asset + '_ret_close2'] = (100*(df[asset]/df[asset + '_close_l2']-1)).shift(1)\n",
    "\n",
    "    cols_todrop = [x for x in list(df.columns) if asset in x and 'ret' not in x]\n",
    "    df.drop(columns = cols_todrop, inplace=True)\n",
    "\n",
    "display(time.time() - time0, df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a8bba9-5d27-47bd-b769-123388864121",
   "metadata": {},
   "outputs": [],
   "source": [
    "### do modeling ###\n",
    "\n",
    "t_df = df.copy()\n",
    "t_df.rename(columns={'VTHR_ret':'target'}, inplace=True)\n",
    "t_df.drop(columns = ['time', 'date', 'Spx_ret', 'Nasdaq_ret', 'Russel_ret', 'EEMA_ret', 'EEM_ret', 'EMXC_ret', 'VXUS_ret'], \n",
    "          inplace=True,\n",
    "          errors = 'ignore')\n",
    "t_df\n",
    "\n",
    "t_df = t_df.dropna()\n",
    "t_df.info()\n",
    "\n",
    "\n",
    "y = t_df.pop('target')\n",
    "X = t_df\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=int(0.2*X.shape[0]))\n",
    "display(X_train.shape, X_test.shape, y_train.shape, X_train.head())\n",
    "\n",
    "time1 = time.time()\n",
    "\n",
    "# xgbm = XGBRegressor()\n",
    "# parameters = {'eta':[0.03, 0.04, 0.05, 0.06, 0.07], \n",
    "#               'max_depth':[2, 3],\n",
    "#              'subsample':[0.6, 0.8],\n",
    "#              'colsample_bytree':[0.6, 0.8]}\n",
    "# xgbgs = GridSearchCV(xgbm, parameters, cv=2)\n",
    "# xgbgs.fit(X_train, y_train)\n",
    "# print(xgbgs.best_params_)\n",
    "# xgbt = XGBRegressor(**xgbgs.best_params_)\n",
    "xgbt = XGBRegressor(n_estimators=500, eta=0.005, max_depth=2, subsample=0.6, colsample_bytree=0.5)\n",
    "xgbt.fit(X_train, y_train)\n",
    "\n",
    "enm = ElasticNet()\n",
    "parameters = {'alpha':[0.0005, 0.001, 0.002, 0.003, 0.005], \n",
    "              'l1_ratio':[0, 0.02, 0.05, 0.1, 0.25, 0.5, 1]}\n",
    "enmgs = GridSearchCV(enm, parameters, scoring='r2', cv=4)\n",
    "enmgs.fit(X_train, y_train)\n",
    "print(enmgs.best_params_)\n",
    "enmt = XGBRegressor(**enmgs.best_params_)\n",
    "enmt.fit(X_train, y_train)\n",
    "\n",
    "print('In sample, xgb: ', r2_score(y_train, xgbt.predict(X_train)))\n",
    "print('Out of sample, xgb: ', r2_score(y_test, xgbt.predict(X_test)))\n",
    "\n",
    "print('In sample, ElasticNet: ', r2_score(y_train, enmgs.predict(X_train)))\n",
    "print('Out of sample, ElasticNet: ', r2_score(y_test, enmgs.predict(X_test)))\n",
    "\n",
    "print('Total time: ', time.time()-time0)\n",
    "\n",
    "\n",
    "# explainerxgbc = shap.TreeExplainer(xgbt)\n",
    "explainerxgbc = shap.Explainer(enmt)\n",
    "\n",
    "shap_values_XGBoost_test = explainerxgbc.shap_values(X_test)\n",
    "shap_values_XGBoost_train = explainerxgbc.shap_values(X_train)\n",
    "\n",
    "vals = np.abs(shap_values_XGBoost_test).mean(0)\n",
    "feature_names = X_test.columns\n",
    "feature_importance = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                 columns=['col_name','feature_importance_vals'])\n",
    "feature_importance.sort_values(by=['feature_importance_vals'],\n",
    "                              ascending=False, inplace=True)\n",
    "\n",
    "shap.summary_plot(shap_values_XGBoost_test, X_test, plot_type=\"bar\", plot_size=(6,6), max_display=20)\n",
    "shap.summary_plot(shap_values_XGBoost_train, X_train,plot_type=\"dot\", plot_size=(6,6), max_display=20)\n",
    "\n",
    "# xgboost sucks here\n",
    "# takeaway is that to do regression with xgboost I need more observations than to do classification\n",
    "# 5,000 obs is definitely not enough for xgb regression, so it is not even worth trying.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(f'''minimum and maximum values in train sample are \n",
    "{y_train.min()}, {y_train.max()}''')\n",
    "print(f'''minimum and maximum values in test sample are \n",
    "{y_test.min()}, {y_test.max()}''')\n",
    "\n",
    "print(f'''predicted minimum and maximum values in train sample are \n",
    "{enmt.predict(X_train).min()}, {enmt.predict(X_train).max()}''')\n",
    "print(f'''predicted minimum and maximum values in test sample are \n",
    "{enmt.predict(X_test).min()}, {enmt.predict(X_test).max()}''')\n",
    "\n",
    "may want to add truncation to predicted values later\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4944147f-c44d-4b71-adce-8be72de918b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33734969-c635-40b1-97ce-2c48f517e6b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0d07a2-2d53-46fd-9442-50b1fbf8ce14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b090848-14c1-4db6-b22b-0ad33f8c8bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2058cf7-cdc6-45e3-a5e5-b389bd64dcc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f34152c-3a4d-41e3-a3c3-0714e4d20fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m100",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
